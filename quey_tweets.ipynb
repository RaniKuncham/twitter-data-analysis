{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78044880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    id           event                               ts1  \\\n",
      "0  1131594960443199488  britney_201904  2022-02-28 09:34:44.627023-05:00   \n",
      "1  1131594976750653440  britney_201904  2022-02-28 09:34:44.626921-05:00   \n",
      "2  1131589737955942405  britney_201904  2022-02-28 09:34:44.634058-05:00   \n",
      "3  1131594909469892610  britney_201904  2022-02-28 09:34:44.627125-05:00   \n",
      "4  1131594812694511617  britney_201904  2022-02-28 09:34:44.627227-05:00   \n",
      "\n",
      "                                ts2  from_stream  directly_from_stream  \\\n",
      "0  2022-02-28 09:34:44.627023-05:00         True                  True   \n",
      "1  2022-02-28 09:34:44.626921-05:00         True                  True   \n",
      "2  2022-02-28 09:34:44.634058-05:00         True                  True   \n",
      "3  2022-02-28 09:34:44.627125-05:00         True                  True   \n",
      "4  2022-02-28 09:34:44.627227-05:00         True                  True   \n",
      "\n",
      "   from_search  directly_from_search  from_quote_search  \\\n",
      "0        False                 False              False   \n",
      "1        False                 False              False   \n",
      "2        False                 False              False   \n",
      "3        False                 False              False   \n",
      "4        False                 False              False   \n",
      "\n",
      "   directly_from_quote_search  ...            retweeted  retweeted_author_id  \\\n",
      "0                       False  ...  1130917791752757254           3042894016   \n",
      "1                       False  ...                 None                 None   \n",
      "2                       False  ...                 None                 None   \n",
      "3                       False  ...  1130917791752757254           3042894016   \n",
      "4                       False  ...  1130917791752757254           3042894016   \n",
      "\n",
      "   retweeted_handle  retweeted_follower_count mentioned_author_ids  \\\n",
      "0          Iesbwian                     22760                 None   \n",
      "1              None                      None                 None   \n",
      "2              None                      None                 None   \n",
      "3          Iesbwian                     22760                 None   \n",
      "4          Iesbwian                     22760                 None   \n",
      "\n",
      "  mentioned_handles  hashtags  urls media_keys  place_id  \n",
      "0              None      None  None       None      None  \n",
      "1              None      None  None       None      None  \n",
      "2              None      None  None       None      None  \n",
      "3              None      None  None       None      None  \n",
      "4              None      None  None       None      None  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def load_data(file_path,chunk_size=None):\n",
    "    if chunk_size:\n",
    "        chunks = pd.read_csv(file_path, sep ='\\t', chunksize=chunk_size)\n",
    "        df =pd.concat(chunks, ignore_index=True)\n",
    "    else:\n",
    "        df=pd.read_csv(file_path,sep='\\t')\n",
    "    return df\n",
    "file_path=\"C:\\\\Users\\\\kunch\\\\Downloads\\\\correct_twitter_201904.tsv\"\n",
    "df=load_data(file_path)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5971ac3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tweets per day:\n",
      " date\n",
      "2019-03-12      3\n",
      "2019-04-06      1\n",
      "2019-04-14      1\n",
      "2019-04-16      1\n",
      "2019-04-21      1\n",
      "2019-04-24      1\n",
      "2019-04-26      2\n",
      "2019-04-27      2\n",
      "2019-04-28     32\n",
      "2019-04-29    163\n",
      "2019-04-30     93\n",
      "2019-05-01     71\n",
      "2019-05-02     68\n",
      "2019-05-03    110\n",
      "2019-05-04     69\n",
      "2019-05-05     70\n",
      "2019-05-06     62\n",
      "2019-05-07     71\n",
      "2019-05-08     58\n",
      "2019-05-09    172\n",
      "2019-05-10    201\n",
      "2019-05-11     86\n",
      "2019-05-12     61\n",
      "2019-05-13     53\n",
      "2019-05-14     68\n",
      "2019-05-15    103\n",
      "2019-05-16     96\n",
      "2019-05-17    159\n",
      "2019-05-18     53\n",
      "2019-05-19     41\n",
      "2019-05-20     86\n",
      "2019-05-21    102\n",
      "2019-05-22     95\n",
      "2019-05-23     57\n",
      "2019-05-24     49\n",
      "2019-05-25    120\n",
      "2019-05-26     94\n",
      "2019-05-27     71\n",
      "2019-05-28    149\n",
      "2019-05-29    133\n",
      "2019-05-30     73\n",
      "dtype: int64\n",
      "\n",
      "Unique users count: 2109\n",
      "\n",
      "Average likes: 161.40853048983672\n",
      "\n",
      "Locations (Place IDs): ['None' '53504716d445dcad' 'ab2f2fac83aa388d' '0113afc024d5e0bc'\n",
      " '300bcc6e23a88361' '8e9665cec9370f0f' 'd56c5babcffde8ef'\n",
      " '01153d1b33e1641b' '09f6a7707f18e0b1' '714789cf3b7a50d0'\n",
      " '01fbe706f872cb32' '1a7a70d4a28e96a1' 'f97108ab3c4a42ed'\n",
      " 'ac88a4f17a51c7fc' '5de8cffc145c486b' '3f7a925ec706ea48'\n",
      " '001aff55522d96c9' '4c8e28554110ebcf' '5c62ffb0f0f3479d'\n",
      " '3b77caf94bfc81fe' 'ecbe2aea853af44e' 'de599025180e2ee7'\n",
      " '00b673715a35dfa7' '43d2418301bf1a49' '07e9c7d1954fff64'\n",
      " '0570f015c264cbd9' '0149775319466b18' '91890dbb74364d63'\n",
      " '01ddb0100b1efd97' 'b49b3053b5c25bf5' '7cb7440bcf83d464'\n",
      " '151b9e91272233d1' '9d63050d3d33d32f' '140800566259f12f'\n",
      " '743df94d8dcb69a6' '8bc4eeacf63235f9' '8943f93b51e3f357'\n",
      " '2bc7c264a080898b' '814cfc71b843ff40' '2b8922cbe7f16337'\n",
      " '7de31e05e99a00f8']\n",
      "\n",
      "Tweet times (hours):\n",
      " hour\n",
      "0     135\n",
      "1     119\n",
      "2      89\n",
      "3      85\n",
      "4      99\n",
      "5      94\n",
      "6      70\n",
      "7      55\n",
      "8     107\n",
      "9     130\n",
      "10    151\n",
      "11    147\n",
      "12    122\n",
      "13    137\n",
      "14    152\n",
      "15    163\n",
      "16    120\n",
      "17    110\n",
      "18    146\n",
      "19    136\n",
      "20    159\n",
      "21    154\n",
      "22    166\n",
      "23    155\n",
      "dtype: int64\n",
      "\n",
      "User who posted the most tweets: 118301422\n"
     ]
    }
   ],
   "source": [
    "def tweets_per_day(df,term):\n",
    "    df_filtered =df[df['text'].str.contains(term, case=False, na=False)].copy()\n",
    "    df_filtered['date'] = pd.to_datetime(df_filtered['created_at']).dt.date\n",
    "    return df_filtered.groupby('date').size()\n",
    "def unique_users(df,term):\n",
    "    df_filtered =df[df['text'].str.contains(term, case=False, na=False)]\n",
    "    return df_filtered['author_id'].nunique()\n",
    "def avg_likes(df,term):\n",
    "    df_filtered =df[df['text'].str.contains(term, case=False, na=False)]\n",
    "    return df_filtered['like_count'].mean()\n",
    "def tweet_locations(df,term):\n",
    "    df_filtered =df[df['text'].str.contains(term, case=False,na=False)]\n",
    "    return df_filtered['place_id'].dropna().unique()\n",
    "def tweet_times(df,term):\n",
    "    df_filtered =df[df['text'].str.contains(term, case=False, na=False)].copy()\n",
    "    df_filtered['hour'] = pd.to_datetime(df_filtered['created_at']).dt.hour\n",
    "    return df_filtered.groupby('hour').size()\n",
    "def top_user(df,term):\n",
    "    df_filtered =df[df['text'].str.contains(term, case=False, na=False)].copy()\n",
    "    return df_filtered['author_id'].value_counts().idxmax()\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\kunch\\\\Downloads\\\\correct_twitter_201904.tsv\", sep='\\t')\n",
    "search_term=\"music\"\n",
    "# Load the dataset\n",
    "#df = pd.read_csv('your_dataset.tsv', sep='\\t')\n",
    "\n",
    "# Define the search term\n",
    "#search_term = \"music\"\n",
    "\n",
    "# Run the queries for the search term\n",
    "tweets_day = tweets_per_day(df, search_term)\n",
    "unique_users_count = unique_users(df, search_term)\n",
    "average_likes = avg_likes(df, search_term)\n",
    "locations = tweet_locations(df, search_term)\n",
    "tweet_times_distribution = tweet_times(df, search_term)\n",
    "most_frequent_user = top_user(df, search_term)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nTweets per day:\\n\", tweets_day)\n",
    "print(\"\\nUnique users count:\", unique_users_count)\n",
    "print(\"\\nAverage likes:\", average_likes)\n",
    "print(\"\\nLocations (Place IDs):\", locations)\n",
    "print(\"\\nTweet times (hours):\\n\", tweet_times_distribution)\n",
    "print(\"\\nUser who posted the most tweets:\", most_frequent_user)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2b8fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
